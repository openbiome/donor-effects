import csv
import requests, hashlib, wget
from pathlib import Path

configfile: "config.yaml"

# Functions -----------------------------------------------------------

def csv_columns(fn):
    with open(fn) as f:
        rows = [x for x in csv.DictReader(f)]

    return {k: [row[k] for row in rows] for k in rows[0].keys()}

def download(url, filepath, md5):
    if not Path(filepath).exists():
        wget.download(url, filepath)

    with open(filepath, "rb") as f:
        observed_md5 = hashlib.md5(f.read()).hexdigest()
        if not observed_md5 == md5:
            raise RuntimeError(f"Downloaded file {filepath} from url {url}"
                "has MD5 {observed_md5}, which does not match file manifest's"
                "expected MD5 {md5}")

def minimum_depth(fn):
    '''Get minimum number of counts in OTU table across samples'''
    return int(pd.read_csv(fn, sep="\t", header=1).drop("#OTU ID", axis=1).apply(sum, axis=0).min())

# Load the samples filename -------------------------------------------

samples_fn = "samples.csv"

if not Path(samples_fn).exists():
    print("Making manifest before constructing DAG...")
    subprocess.run("./make-manifest.R")

samples = csv_columns(samples_fn)


# Rules ---------------------------------------------------------------

rule all:
    input:
        config["alpha-diversity"]

rule export_diversity:
    output:
        "alpha-diversity.tsv"
    input:
        config["alpha-diversity"]
    shell:
        "qiime tools export --input-path {input} --output-path ."

rule diversity:
    output:
        config["alpha-diversity"]
    input:
        config["rarefied-table"]
    params:
        metric = config["alpha-diversity-metric"]
    shell:
        "qiime diversity alpha"
        " --i-table {input}"
        " --p-metric {params.metric}"
        " --o-alpha-diversity {output}"

rule rarefy:
    output:
        config["rarefied-table"]
    input:
        config["table"]
    params:
        depth = open(config["rarefaction-depth"]).read()
    shell:
        "qiime feature-table rarefy"
        " --i-table {input}"
        " --p-sampling-depth {params.depth}"
        " --o-rarefied-table {output}"

rule compute_depth:
    output:
        config["rarefaction-depth"]
    input:
        config["table-tsv"]
    run:
        with open(output[0], 'w') as f:
            f.write(str(minimum_depth(input[0])))

rule convert_table:
    output:
        config["table-tsv"]
    input:
        "feature-table.biom"
    shell:
        "biom convert --to-tsv -i {input} -o {output}"

rule export_table:
    output:
        "feature-table.biom"
    input:
        config["table"]
    shell:
        "qiime tools export --input-path {input} --output-path ."

rule denoise:
    output:
        table = config["table"],
        seqs = config["rep-seqs"],
        stats = config["denoise-stats"]
    input:
        config["filter"]
    params:
        trim_length = config["trim-length"],
        min_reads = config["min-reads"],
        jobs_to_start = config["jobs-to-start"]
    shell:
        "qiime deblur denoise-16S"
        " --i-demultiplexed-seqs {input}"
        " --p-trim-length {params.trim_length}"
        " --p-min-reads {params.min_reads}"
        " --p-jobs-to-start {params.jobs_to_start}"
        " --p-sample-stats"
        " --o-table {output.table}"
        " --o-representative-sequences {output.seqs}"
        " --o-stats {output.stats}"

rule filter:
    output:
        filter = config["filter"],
        stats = config["filter-stats"]
    input:
        config["demux"]
    shell:
        "qiime quality-filter q-score "
        " --i-demux {input}"
        " --o-filtered-sequences {output.filter}"
        " --o-filter-stats {output.stats}"

rule demultiplex:
    output:
        config["demux"]
    input:
        samples["filepath"],
        manifest = config["manifest"]
    shell:
        "qiime tools import"
        " --type 'SampleData[SequencesWithQuality']"
        " --input-path {input.manifest}"
        " --input-format SingleEndFastqManifestPhred33"
        " --output-path {output}"

rule download_fastq:
    params:
        url = samples["url"],
        md5 = samples["fastq_md5"]
    output:
        samples["filepath"]
    run:
        for url, filepath, md5 in zip(params.url, output, params.md5):
            print(url, filepath, md5)
            download_and_validate(url, filepath, md5)
